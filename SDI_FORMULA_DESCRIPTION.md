# Locust-SDI: Математическая модель индекса деградации системы

## Введение

Locust-SDI (System Degradation Index) — это академический индекс для количественной оценки деградации производительности веб-систем под нагрузкой. Индекс разработан на основе анализа метрик нагрузочного тестирования и объединяет методы статистического анализа, нормализации данных и теории обнаружения аномалий.

**Диапазон значений:** [0, 1]
- **0.0-0.3** — стабильная работа
- **0.3-0.5** — начало деградации
- **0.5-0.7** — серьёзная деградация
- **>0.7** — критическое состояние

---

## 1. Математическая основа

### 1.1. Основная формула

Locust-SDI представляет собой взвешенную комбинацию трёх компонентов деградации:

```
SDI = Σ wₘ · Dₘ
      m∈M
```

где:
- `M = {rt_avg, rt_95, rt_99, error_rate, rps}` — множество отслеживаемых метрик
- `wₘ` — вес метрики m в итоговом индексе
- `Dₘ` — степень деградации метрики m

### 1.2. Декомпозиция деградации метрики

Каждая метрика оценивается по трём независимым аспектам:

```
Dₘ = α·D^(A)ₘ + β·D^(T)ₘ + γ·D^(S)ₘ
```

где:
- **D^(A)ₘ** — амплитудная деградация (отклонение от нормы)
- **D^(T)ₘ** — трендовая деградация (скорость ухудшения)
- **D^(S)ₘ** — деградация от нестабильности (аномальные скачки)
- **α, β, γ** — весовые коэффициенты компонентов (α + β + γ = 1)

**Стандартные веса:** α=0.4, β=0.3, γ=0.3

---

## 2. Компонент 1: Амплитудная деградация D^(A)

### 2.1. Назначение
Измеряет **абсолютное отклонение** текущего значения метрики от эталонного (baseline) относительно критического порога.

### 2.2. Метод нормализации

**Для метрик роста** (rt_avg, rt_95, rt_99, error_rate):

```
D^(A)ₘ = (vₘ - v_ref) / (v_crit - v_ref)
```

**Для метрик падения** (rps):

```
D^(A)ₘ = (v_ref - vₘ) / (v_ref - v_crit)
```

где:
- `vₘ` — текущее значение метрики
- `v_ref` — эталонное значение (при малой нагрузке)
- `v_crit` — критическое значение (SLA или порог отказа)

**Ограничение:** D^(A)ₘ ∈ [0, 1]

### 2.3. Математическое обоснование

Используется **линейная интерполяция** между эталонным и критическим значениями. Этот метод основан на предположении о линейной деградации производительности в диапазоне [v_ref, v_crit].

**Свойства:**
- D^(A)ₘ = 0 при vₘ = v_ref (идеальное состояние)
- D^(A)ₘ = 1 при vₘ = v_crit (критическое состояние)
- Монотонность: рост метрики → рост деградации

### 2.4. Пример расчёта

Дано:
- rt_avg_ref = 50ms (эталонное время отклика)
- rt_avg_crit = 500ms (критическое время отклика)
- rt_avg_current = 200ms (текущее время отклика)

Расчёт:
```
D^(A)_rt_avg = (200 - 50) / (500 - 50) = 150 / 450 = 0.333
```

Интерпретация: Текущее время отклика на 33.3% пути от нормы к критическому состоянию.

---

## 3. Компонент 2: Трендовая деградация D^(T)

### 3.1. Назначение
Измеряет **скорость ухудшения** метрики — насколько быстро система деградирует во времени.

### 3.2. Формула

**Для метрик роста:**

```
D^(T)ₘ = Δvₘ / (v_crit - v_ref)
```

**Для метрик падения (rps):**

```
D^(T)_rps = (v_prev - v_curr) / (v_ref - v_crit)
```

где:
- `Δvₘ = v_curr - v_prev` — изменение метрики за интервал Δt
- `Δt` — временной интервал между измерениями (обычно monitoring_interval)

**Ограничение:** D^(T)ₘ ∈ [0, 1]

### 3.3. Математическое обоснование

Трендовый компонент основан на **методе конечных разностей** для оценки производной:

```
dv/dt ≈ Δv/Δt = (v_curr - v_prev) / Δt
```

Нормализация производной относительно критического диапазона позволяет оценить, какую долю от допустимого изменения метрика прошла за один временной интервал.

**Физический смысл:**
- D^(T) = 0 — метрика стабильна или улучшается
- D^(T) = 1 — метрика меняется с максимальной скоростью

### 3.4. Пример расчёта

Дано:
- rt_95_prev = 300ms (предыдущее значение)
- rt_95_curr = 450ms (текущее значение)
- rt_95_ref = 100ms, rt_95_crit = 1000ms

Расчёт:
```
Δrt_95 = 450 - 300 = 150ms
D^(T)_rt_95 = 150 / (1000 - 100) = 150 / 900 = 0.167
```

Интерпретация: За один интервал мониторинга метрика P95 прошла 16.7% пути от нормы к критическому значению.

---

## 4. Компонент 3: Деградация от нестабильности D^(S)

### 4.1. Назначение
Обнаруживает **аномальные скачки** (spikes) в метриках — внезапные отклонения от среднего поведения.

### 4.2. Формула

Используется модифицированный **z-score** (стандартизированное отклонение):

```
D^(S)ₘ = min(1, |vₘ - μ| / (σ + ε))
```

где:
- `vₘ` — текущее значение метрики
- `μ = mean(window)` — среднее значение в скользящем окне
- `σ = std(window)` — стандартное отклонение в окне
- `window` — последние N измерений (обычно N=10)
- `ε = 1e-6` — константа для предотвращения деления на ноль

### 4.3. Математическое обоснование

**Z-score** — классический метод обнаружения аномалий в статистике:

```
z = (x - μ) / σ
```

Где z показывает, на сколько стандартных отклонений точка удалена от среднего.

**Для нормального распределения:**
- |z| < 1 — 68% значений (норма)
- |z| < 2 — 95% значений (небольшое отклонение)
- |z| > 3 — <1% значений (аномалия)

В нашем случае используется **нормированная версия** с ограничением [0, 1], где:
- D^(S) = 0 — значение близко к среднему
- D^(S) = 1 — сильный выброс (spike)

### 4.4. Расчёт среднего и стандартного отклонения

**Среднее значение** (выборочное среднее):

```
μ = (1/N) Σ vᵢ
        i=1..N
```

**Дисперсия** (выборочная дисперсия):

```
σ² = (1/N) Σ (vᵢ - μ)²
         i=1..N
```

**Стандартное отклонение:**

```
σ = √(σ²)
```

### 4.5. Пример расчёта

Дано (скользящее окно rt_99, последние 10 измерений):
```
window = [400, 420, 410, 430, 415, 425, 418, 422, 900, 428] # в мс
```

Расчёт:
1. Среднее:
   ```
   μ = (400+420+...+428) / 10 = 4668 / 10 = 466.8 ms
   ```

2. Дисперсия:
   ```
   σ² = [(400-466.8)² + (420-466.8)² + ... + (428-466.8)²] / 10
   σ² = [4462.24 + 2190.24 + ... + 1507.24] / 10 = 22816.4
   ```

3. Стандартное отклонение:
   ```
   σ = √22816.4 ≈ 151.05 ms
   ```

4. Spike для последнего значения (900ms):
   ```
   D^(S)_rt_99 = |900 - 466.8| / (151.05 + 1e-6)
               = 433.2 / 151.05
               = 2.868
   ```

5. Ограничение:
   ```
   D^(S)_rt_99 = min(1, 2.868) = 1.0
   ```

Интерпретация: Обнаружен сильный spike (выброс) — значение 900ms отклоняется от среднего на 2.87 стандартных отклонений, что является аномалией.

---

## 5. Весовые коэффициенты

### 5.1. Веса компонентов деградации

Определяют важность каждого аспекта деградации:

```
α = 0.4  — амплитуда (текущее состояние)
β = 0.3  — тренд (динамика изменений)
γ = 0.3  — spike (нестабильность)
```

**Обоснование:**
- **Амплитуда** получает больший вес, так как абсолютное отклонение от нормы — главный индикатор деградации
- **Тренд** и **Spike** дополняют картину, показывая скорость ухудшения и стабильность системы
- Сумма весов: α + β + γ = 1 (нормированная комбинация)

### 5.2. Веса метрик

Определяют важность каждой метрики в итоговом индексе:

```
w_rt_95      = 0.30  (30%)  — P95 латентность
w_rt_99      = 0.25  (25%)  — P99 латентность
w_error_rate = 0.25  (25%)  — Процент ошибок
w_rps        = 0.15  (15%)  — Пропускная способность
w_rt_avg     = 0.05  (5%)   — Средняя латентность
```

**Обоснование:**

1. **rt_95 (30%)** — наибольший вес:
   - Отражает реальный пользовательский опыт
   - 95% запросов не должны превышать SLA
   - Балансирует между средним и экстремальными значениями

2. **rt_99 (25%)** — высокий вес:
   - Показывает поведение "в хвосте" распределения
   - Критично для latency-sensitive приложений
   - Индикатор редких, но значимых задержек

3. **error_rate (25%)** — высокий вес:
   - Напрямую влияет на функциональность
   - Любой рост ошибок — признак проблем
   - Критический фактор надежности

4. **rps (15%)** — умеренный вес:
   - Показывает пропускную способность
   - Падение RPS при росте нагрузки — явный признак деградации
   - Менее критичен чем латентность и ошибки

5. **rt_avg (5%)** — минимальный вес:
   - Может скрывать проблемы из-за усреднения
   - Менее показателен чем перцентили
   - Используется как дополнительный индикатор

**Сумма весов:** Σwₘ = 1.0

### 5.3. Обоснование выбора весов

Веса основаны на:

1. **Практике SRE (Site Reliability Engineering):**
   - Google SRE рекомендует фокусироваться на перцентилях (P95, P99)
   - Error budget — процент допустимых ошибок

2. **Исследованиях производительности:**
   - "The Tail at Scale" (Dean & Barroso, 2013) — важность P99
   - "Latency Lags Bandwidth" (Patterson, 2004) — влияние латентности

3. **Эмпирическом анализе:**
   - Анализ корреляции метрик с реальными инцидентами
   - Статистика деградации в production-системах

---

## 6. Итоговая формула Locust-SDI

### 6.1. Полная развёрнутая форма

```
SDI = Σ wₘ · min(1, α·D^(A)ₘ + β·D^(T)ₘ + γ·D^(S)ₘ)
      m∈M
```

где каждый компонент вычисляется как:

**Амплитуда:**
```
D^(A)ₘ = (vₘ - v_ref) / (v_crit - v_ref)  для метрик роста
D^(A)ₘ = (v_ref - vₘ) / (v_ref - v_crit)  для метрик падения (rps)
```

**Тренд:**
```
D^(T)ₘ = (v_curr - v_prev) / (v_crit - v_ref)  для метрик роста
D^(T)ₘ = (v_prev - v_curr) / (v_ref - v_crit)  для метрик падения
```

**Spike:**
```
D^(S)ₘ = min(1, |vₘ - μ_window| / (σ_window + ε))
```

### 6.2. Подстановка весовых коэффициентов

```
SDI = 0.30 · D_rt_95 +
      0.25 · D_rt_99 +
      0.25 · D_error_rate +
      0.15 · D_rps +
      0.05 · D_rt_avg

где:
D_m = min(1, 0.4·D^(A)ₘ + 0.3·D^(T)ₘ + 0.3·D^(S)ₘ)
```

### 6.3. Алгоритм вычисления

**Входные данные:**
- `curr` — текущие метрики (RawMetrics)
- `prev` — предыдущие метрики (RawMetrics)
- `history` — история метрик (list[RawMetrics])
- `ref` — эталонные значения (ReferenceMetrics)

**Шаги:**

1. **Вычислить амплитудную деградацию** для каждой метрики:
   ```python
   for m in [rt_avg, rt_95, rt_99, error_rate, rps]:
       D_A[m] = normalize_metric_growth(curr[m], ref[m]_ref, ref[m]_crit)
   ```

2. **Вычислить трендовую деградацию:**
   ```python
   for m in [rt_avg, rt_95, rt_99, error_rate, rps]:
       delta = curr[m] - prev[m]
       D_T[m] = delta / (ref[m]_crit - ref[m]_ref)
   ```

3. **Вычислить spike-деградацию** (скользящее окно N=10):
   ```python
   for m in [rt_avg, rt_95, rt_99, error_rate, rps]:
       window = [h[m] for h in history[-10:]]
       mean = sum(window) / len(window)
       std = sqrt(sum((x - mean)^2 for x in window) / len(window))
       D_S[m] = min(1, abs(curr[m] - mean) / (std + 1e-6))
   ```

4. **Агрегировать компоненты** для каждой метрики:
   ```python
   for m in metrics:
       D[m] = min(1, 0.4*D_A[m] + 0.3*D_T[m] + 0.3*D_S[m])
   ```

5. **Вычислить итоговый SDI** (взвешенная сумма):
   ```python
   SDI = 0.30*D[rt_95] + 0.25*D[rt_99] + 0.25*D[error_rate] +
         0.15*D[rps] + 0.05*D[rt_avg]
   ```

6. **Ограничить диапазон:**
   ```python
   SDI = max(0, min(1, SDI))
   ```

---

## 7. Математический аппарат

Формула Locust-SDI использует следующие математические методы:

### 7.1. Линейная нормализация (Min-Max Scaling)

Преобразование значения из диапазона [a, b] в [0, 1]:

```
x_norm = (x - a) / (b - a)
```

**Применение:** Нормализация амплитудной и трендовой деградации.

**Источник:** Стандартный метод нормализации в машинном обучении и статистике.

### 7.2. Z-score (Стандартизация)

Измеряет отклонение от среднего в единицах стандартного отклонения:

```
z = (x - μ) / σ
```

**Применение:** Обнаружение spike-аномалий.

**Источник:**
- Gosset, W. S. (1908). "The Probable Error of a Mean"
- Классический метод в статистическом анализе выбросов

### 7.3. Взвешенная сумма (Weighted Sum)

Линейная комбинация компонентов с весовыми коэффициентами:

```
y = Σ wᵢ · xᵢ,  где Σ wᵢ = 1
```

**Применение:** Агрегация компонентов деградации и метрик.

**Источник:** Многокритериальный анализ решений (MCDM).

### 7.4. Метод конечных разностей

Численная аппроксимация производной:

```
f'(t) ≈ [f(t) - f(t-Δt)] / Δt
```

**Применение:** Оценка скорости изменения метрик (тренд).

**Источник:** Численные методы математического анализа.

### 7.5. Скользящее окно (Sliding Window)

Анализ данных в фиксированном окне последних N наблюдений:

```
window(t) = {x(t-N+1), x(t-N+2), ..., x(t)}
```

**Применение:** Расчёт статистик для spike-detection.

**Источник:** Временные ряды и потоковый анализ данных.

---

## 8. Интерпретация результатов

### 8.1. Градации индекса

| SDI        | Состояние              | Характеристика                                    |
|------------|------------------------|---------------------------------------------------|
| 0.0 - 0.3  | Стабильная работа      | Система работает в пределах нормы                 |
| 0.3 - 0.5  | Начало деградации      | Появляются первые признаки ухудшения              |
| 0.5 - 0.7  | Серьёзная деградация   | Метрики значительно отклонились от нормы          |
| 0.7 - 1.0  | Критическое состояние  | Система близка к отказу или уже отказывает        |

### 8.2. Пример интерпретации

**Сценарий:** SDI = 0.62

**Детализация по компонентам:**
```
D_rt_95      = 0.55 (вклад: 0.30 * 0.55 = 0.165)
D_rt_99      = 0.70 (вклад: 0.25 * 0.70 = 0.175)
D_error_rate = 0.45 (вклад: 0.25 * 0.45 = 0.112)
D_rps        = 0.80 (вклад: 0.15 * 0.80 = 0.120)
D_rt_avg     = 0.50 (вклад: 0.05 * 0.50 = 0.025)
                     Итого SDI = 0.597 ≈ 0.60
```

**Вывод:**
- Система находится в состоянии серьёзной деградации
- Основные проблемы: падение RPS (0.80) и рост P99 (0.70)
- Рекомендуется остановка теста с текущей нагрузкой

---

## 9. Преимущества формулы

1. **Многомерность:** Учитывает 5 ключевых метрик производительности
2. **Многоаспектность:** Анализирует амплитуду, тренд и нестабильность
3. **Нормализация:** Все компоненты приведены к единой шкале [0, 1]
4. **Статистическая обоснованность:** Использует проверенные методы (z-score, линейная интерполяция)
5. **Настраиваемость:** Веса можно адаптировать под конкретные требования системы
6. **Интерпретируемость:** Понятная шкала и градации состояний

---

## 10. Научные источники и обоснование

### 10.1. Методы обнаружения аномалий

- **Z-score:** Grubbs, F. E. (1969). "Procedures for Detecting Outlying Observations in Samples"
- **Statistical Process Control:** Shewhart, W. A. (1931). "Economic Control of Quality of Manufactured Product"

### 10.2. Метрики производительности веб-систем

- **Latency Percentiles:** Dean, J., & Barroso, L. A. (2013). "The Tail at Scale"
- **Site Reliability Engineering:** Beyer, B. et al. (2016). "Site Reliability Engineering: How Google Runs Production Systems"

### 10.3. Нормализация и взвешивание

- **Min-Max Normalization:** Jain, A., Nandakumar, K., & Ross, A. (2005). "Score normalization in multimodal biometric systems"
- **Weighted Aggregation:** Saaty, T. L. (1980). "The Analytic Hierarchy Process"

### 10.4. Временные ряды

- **Sliding Window Analysis:** Keogh, E., & Lin, J. (2005). "Clustering of time-series subsequences is meaningless"
- **Finite Differences:** Press, W. H. et al. (2007). "Numerical Recipes"

---

## Заключение

Locust-SDI представляет собой комплексный математически обоснованный индекс для оценки деградации систем под нагрузкой. Формула сочетает классические статистические методы с практиками мониторинга производительности, обеспечивая точное и интерпретируемое измерение состояния системы.

Использование трёхкомпонентной модели (амплитуда, тренд, spike) позволяет уловить различные аспекты деградации, а взвешенная агрегация метрик учитывает их относительную важность для общей производительности системы.